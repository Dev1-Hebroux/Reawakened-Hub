import pandas as pd
from datetime import datetime, timedelta
import os, re, json

# Load the previously generated "global" import files as the starting point
sparks_csv = "/mnt/data/sparks_db_import_2026-01-19_to_2026-02-17.csv"
refl_csv = "/mnt/data/reflection_cards_db_import_2026-01-19_to_2026-02-17.csv"

sparks_df = pd.read_csv(sparks_csv)
refl_df = pd.read_csv(refl_csv)

segments = ["schools", "universities", "early-career", "builders", "couples"]

# --- Helpers for light tailoring ---
def tailor_spark(row, seg):
    r = row.copy()
    r["audience_segment"] = seg
    
    # Tailor description with one extra contextual sentence (keeps it "slight")
    context_sentence = {
        "schools": "If school or college feels intense right now, this is a simple way to reset your day.",
        "universities": "If campus life feels noisy or pressured, let this be your daily anchor.",
        "early-career": "If your workday feels full and fast, take this as a quick reset before you push on.",
        "builders": "If you’re building something—projects, a business, a team—let this steady your inner life.",
        "couples": "If you’re navigating relationship pressure or decisions, let this help you stay steady together."
    }[seg]
    
    desc = str(r["description"]).strip()
    # Insert after first sentence if possible
    parts = re.split(r"(?<=[.!?])\s+", desc, maxsplit=1)
    if len(parts) == 2:
        r["description"] = f"{parts[0]} {context_sentence} {parts[1]}"
    else:
        r["description"] = f"{desc} {context_sentence}"
    
    # Slightly tailor thumbnail_prompt visuals by segment (text overlay stays the same)
    prompt = str(r["thumbnail_prompt"]).strip()
    prompt_add = {
        "schools": "Add subtle school/college vibe: lockers, notebooks, or classroom texture (abstract, not literal).",
        "universities": "Add subtle campus vibe: lecture hall silhouette or university buildings (abstract, not branded).",
        "early-career": "Add subtle workplace vibe: clean desk, laptop, or city commute elements (abstract).",
        "builders": "Add subtle builder vibe: blueprint lines, startup energy, or product sketch motifs (abstract).",
        "couples": "Add subtle couples vibe: two silhouettes, warm home lighting, or joined hands motif (abstract)."
    }[seg]
    r["thumbnail_prompt"] = f"{prompt} {prompt_add}".strip()
    
    # Light tailoring for prayer_line (optional overlay) without changing theology
    prayer = str(r["prayer_line"]).strip()
    if seg == "schools":
        r["prayer_line"] = prayer.replace("today", "today at school/college")
    elif seg == "universities":
        r["prayer_line"] = prayer.replace("today", "today on campus")
    elif seg == "early-career":
        r["prayer_line"] = prayer.replace("today", "today at work")
    elif seg == "builders":
        r["prayer_line"] = prayer.replace("today", "today as I build")
    elif seg == "couples":
        # Keep it personal but add togetherness cue
        r["prayer_line"] = prayer.replace("me", "us").replace("my", "our")
    
    return r

def tailor_reflection(row, seg):
    r = row.copy()
    r["audience_segment"] = seg
    
    bq = str(r["base_quote"]).strip()
    q = str(r["question"]).strip()
    a = str(r["action"]).strip()
    
    # Segment-specific contextual phrases
    context_q = {
        "schools": " (at school/college)",
        "universities": " (on campus)",
        "early-career": " (at work)",
        "builders": " (as you build)",
        "couples": " (in your relationship)"
    }[seg]
    
    context_a = {
        "schools": "before your next class or revision session",
        "universities": "before your next lecture or seminar",
        "early-career": "before your next meeting or task",
        "builders": "before your next key decision",
        "couples": "with your partner today"
    }[seg]
    
    # Slight tailoring rules (kept minimal)
    if seg in ["schools", "universities", "early-career", "builders"]:
        # Append a short context cue to the question if not already present
        if "(" not in q:
            r["question"] = q + context_q
        else:
            r["question"] = q
        # Add a quick timing cue to the action
        if "before" not in a.lower():
            r["action"] = a + f" Try it {context_a}."
        else:
            r["action"] = a
        # Slightly adjust base quote to feel targeted
        if seg == "schools":
            r["base_quote"] = bq + " You’re allowed to take today one step at a time."
        elif seg == "universities":
            r["base_quote"] = bq + " You don’t have to carry campus pressure alone."
        elif seg == "early-career":
            r["base_quote"] = bq + " Small resets can change how your whole day feels."
        elif seg == "builders":
            r["base_quote"] = bq + " Strong builders protect their inner pace."
    else:
        # Couples: shift toward "we" lightly without rewriting everything
        r["base_quote"] = bq + " This can be a ‘we’ moment, not just a ‘me’ moment."
        # Couple-friendly question
        if "(" not in q:
            r["question"] = q.replace("you", "you both") + context_q
        else:
            r["question"] = q
        # Couple-friendly action
        r["action"] = a + " If you can, share one sentence each about how you’re feeling, then take the next step together."
    
    return r

# --- Build segmented sparks ---
seg_sparks = []
for seg in segments:
    for _, row in sparks_df.iterrows():
        seg_sparks.append(tailor_spark(row, seg))
seg_sparks_df = pd.DataFrame(seg_sparks)

# Ensure column order stays identical to sparks schema import
sparks_col_order = list(sparks_df.columns)
seg_sparks_df = seg_sparks_df[sparks_col_order]

# --- Build segmented reflection cards ---
seg_refl = []
for seg in segments:
    for _, row in refl_df.iterrows():
        seg_refl.append(tailor_reflection(row, seg))
seg_refl_df = pd.DataFrame(seg_refl)

refl_col_order = list(refl_df.columns)
seg_refl_df = seg_refl_df[refl_col_order]

# Validations
assert seg_sparks_df.shape[0] == 30 * len(segments)
assert seg_refl_df.shape[0] == 30 * len(segments)
assert seg_sparks_df["audience_segment"].isin(segments).all()
assert seg_refl_df["audience_segment"].isin(segments).all()

# Save files
base = "/mnt/data"
sparks_seg_csv = os.path.join(base, "sparks_segmented_db_import_2026-01-19_to_2026-02-17.csv")
sparks_seg_json = os.path.join(base, "sparks_segmented_db_import_2026-01-19_to_2026-02-17.json")
refl_seg_csv = os.path.join(base, "reflection_cards_segmented_db_import_2026-01-19_to_2026-02-17.csv")
refl_seg_json = os.path.join(base, "reflection_cards_segmented_db_import_2026-01-19_to_2026-02-17.json")

seg_sparks_df.to_csv(sparks_seg_csv, index=False)
seg_sparks_df.to_json(sparks_seg_json, orient="records", indent=2)
seg_refl_df.to_csv(refl_seg_csv, index=False)
seg_refl_df.to_json(refl_seg_json, orient="records", indent=2)

# Preview
(seg_sparks_df.head(2), seg_sparks_df.tail(2), seg_refl_df.head(2), seg_refl_df.tail(2),
 sparks_seg_csv, sparks_seg_json, refl_seg_csv, refl_seg_json)
